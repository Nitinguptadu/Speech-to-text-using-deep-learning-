{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defines a functions for training a NN.\n",
    "\"\"\"\n",
    "\n",
    "from data_generator import AudioGenerator\n",
    "import _pickle as pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import (Input, Lambda)\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "import os\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def add_ctc_loss(input_to_softmax):\n",
    "    the_labels = Input(name='the_labels', shape=(None,), dtype='float32')\n",
    "    input_lengths = Input(name='input_length', shape=(1,), dtype='int64')\n",
    "    label_lengths = Input(name='label_length', shape=(1,), dtype='int64')\n",
    "    output_lengths = Lambda(input_to_softmax.output_length)(input_lengths)\n",
    "    # CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')(\n",
    "        [input_to_softmax.output, the_labels, output_lengths, label_lengths])\n",
    "    model = Model(\n",
    "        inputs=[input_to_softmax.input, the_labels, input_lengths, label_lengths], \n",
    "        outputs=loss_out)\n",
    "    return model\n",
    "\n",
    "def train_model(input_to_softmax, \n",
    "                pickle_path,\n",
    "                save_model_path,\n",
    "                train_json='train_corpus.json',\n",
    "                valid_json='valid_corpus.json',\n",
    "                minibatch_size=20,\n",
    "                spectrogram=True,\n",
    "                mfcc_dim=13,\n",
    "                optimizer=SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5),\n",
    "                epochs=20,\n",
    "                verbose=1,\n",
    "                sort_by_duration=False,\n",
    "                max_duration=10.0):\n",
    "    \n",
    "    # create a class instance for obtaining batches of data\n",
    "    audio_gen = AudioGenerator(minibatch_size=minibatch_size, \n",
    "        spectrogram=spectrogram, mfcc_dim=mfcc_dim, max_duration=max_duration,\n",
    "        sort_by_duration=sort_by_duration)\n",
    "    # add the training data to the generator\n",
    "    audio_gen.load_train_data(train_json)\n",
    "    audio_gen.load_validation_data(valid_json)\n",
    "    # calculate steps_per_epoch\n",
    "    num_train_examples=len(audio_gen.train_audio_paths)\n",
    "    steps_per_epoch = num_train_examples//minibatch_size\n",
    "    # calculate validation_steps\n",
    "    num_valid_samples = len(audio_gen.valid_audio_paths) \n",
    "    validation_steps = num_valid_samples//minibatch_size\n",
    "    \n",
    "    # add CTC loss to the NN specified in input_to_softmax\n",
    "    model = add_ctc_loss(input_to_softmax)\n",
    "\n",
    "    # CTC loss is implemented elsewhere, so use a dummy lambda function for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "\n",
    "    # make results/ directory, if necessary\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "\n",
    "    # add checkpointer\n",
    "    checkpointer = ModelCheckpoint(filepath='results/'+save_model_path, verbose=0)\n",
    "\n",
    "    # train the model\n",
    "    hist = model.fit_generator(generator=audio_gen.next_train(), steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs, validation_data=audio_gen.next_valid(), validation_steps=validation_steps,\n",
    "        callbacks=[checkpointer], verbose=verbose)\n",
    "\n",
    "    # save model loss\n",
    "    with open('results/'+pickle_path, 'wb') as f:\n",
    "        pickle.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import (BatchNormalization, Conv1D, Dense, Input, \n",
    "    TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM)\n",
    "\n",
    "def bidirectional_rnn_model(input_dim, units, output_dim=29):\n",
    "    \"\"\" Build a bidirectional recurrent network for speech\n",
    "    \"\"\"\n",
    "    # Main acoustic input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    # TODO: Add bidirectional recurrent layer\n",
    "    bidir_rnn = ...\n",
    "    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\n",
    "    time_dense = ...\n",
    "    # Add softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "    # Specify the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: x\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, None, 161)         0         \n",
      "_________________________________________________________________\n",
      "rnn (GRU)                    (None, None, 29)          16617     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 16,617\n",
      "Trainable params: 16,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_0 = simple_rnn_model(input_dim=161) # change to 13 if you would like to use MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 24/106 [=====>........................] - ETA: 29s - loss: 1078.8198"
     ]
    }
   ],
   "source": [
    "train_model(input_to_softmax=model_0, \n",
    "            pickle_path='model_0.pickle', \n",
    "            save_model_path='model_0.h5',\n",
    "            spectrogram=True) # change to False if you would like to use MFCC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(index=0, \n",
    "                partition='train',\n",
    "                input_to_softmax=model_0, \n",
    "                model_path='results/model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
